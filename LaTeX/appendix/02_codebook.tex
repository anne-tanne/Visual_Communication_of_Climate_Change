This codebook serves as a guide for analysing the images generated by \textit{DALL-E} and \textit{Midjourney}. It provides a structured approach to understanding how these models represent extreme weather events, focusing on answering the research questions defined in chapter \ref{section:theoretical-foundations}. In this attempt, the codebook categorises different aspects of the images, allowing for a systematic and detailed examination of the narratives and visual elements depicted in the AI-generated images.

\subsection{Coding Unit}
The primary coding unit (CU) in this study is the single image generated by AI models (\textit{DALL-E} and \textit{Midjourney}). Each image created in response to a specific text prompt is considered a separate unit of analysis.


\textbf{Characteristics of the Coding Unit:
}
\begin{itemize}
    \item \textbf{Completeness}: Images are sourced directly from the AI models and are considered complete as rendered by the AI model, with no subsequent changes or additions.
    \item \textbf{Uniqueness}: Each image is treated as a unique entity, distinct from others generated, even from similar prompts.
    \item \textbf{Relevance}: The image must be relevant to the prompt.
\end{itemize}

This definition ensures that each AI-generated image is analysed in its entirety, focusing on its relevance and alignment with the research themes.

\subsection{General Exclusion Criteria}
In the analysis of AI-generated images, certain categories of content are systematically excluded to maintain focus and relevance to the research questions. The following types of content will not be coded:

\begin{itemize}
    \item \textbf{Off-Topic Imagery:} Images that do not directly correspond to the specific prompts. The focus is on excluding images that are clearly not related to the context or topic of the specific prompt, such as images that show completely unrelated topics or environments.
    \item \textbf{Ineffective Text Generation:} Given the limitations of the AI models \textit{DALL-E} and \textit{Midjourney} in generating coherent and relevant text within images, this study excludes images where the primary focus is on text content. While images simply containing text (without it being the primary focus) are not excluded, the text itself is not analysed. The emphasis is on the visual elements and representations, not on the textual content within the images.
    \item \textbf{Technical Inadequacies:} Images suffering from poor rendering, low resolution, or other technical flaws that significantly hinder their analysis.
\end{itemize}


\subsection{Formal Categories}
 \subsubsection*{CU (Coding Unit)} 
 \addcontentsline{toc}{subsubsection}{CU (Coding Unit)}

 This represents a unique identifier for each individual image generated by the AI models. The ID is derived from the image's filename, for example, \texttt{1\_DALL-E}, signifying the first image created by \textit{DALL-E}.
 
 \subsubsection*{CODER} 
  \addcontentsline{to}{subsubsection}{CODER}

 This category lists the coders involved in the image analysis, each assigned a specific number for identification purposes.
\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] Anne-Sophie Skarabis
\item[2] Linda Murray
\end{description}

 \subsubsection*{MODEL} 
 \addcontentsline{toc}{subsubsection}{MODEL}

 This category indicates the AI model used to generate each image, distinguishing between the two different platforms used in this study.The model can be derived from the image's filename, for example, \texttt{19\_Midjourney}, signifying the 19th image created by Midjourney.

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] \textit{DALL-E 3}
\item[2] \textit{Midjourney v5.2}
\end{description}

\subsubsection*{PROMPT}
\addcontentsline{toc}{subsubsection}{PROMPT}

 The specific text prompt used for generating each image.

 \subsubsection*{DATE} 
 \addcontentsline{toc}{subsubsection}{DATE}

The date on which the image was generated.
\subsection{Narrative Constructs}

This section of the codebook is devoted to the analysis of the narratives constructed by the AI models in the imagery related to extreme weather events. It considers how these events are visually represented in terms of catastrophe, challenge, or opportunity.

\subsubsection*{EVENT (Event Portrayal)}
\addcontentsline{toc}{subsubsection}{EVENT (Event Portrayal)}
The portrayal of events in the images is coded according to the types and impacts of extreme weather events as described in the IPCC policy document. The codes are defined as follows:

\begin{description}[leftmargin=2.5cm, style = multiline, labelwidth=1.5cm]
\item[0] \textbf{Not Applicable}: The image does not depict any recognisable weather-related event.
\item[1] \textbf{Temperature Extremes}: Images depicting unusually hot or cold temperatures, differing significantly from regional historical averages.
\item[2] \textbf{Heavy Precipitation and Pluvial Floods}: Images showing intense rainfall leading to rapid urban and pluvial flooding.
\item[3] \textbf{River Floods}: Images of excessive river and stream levels causing adjacent land inundation.
\item[4] \textbf{Droughts}: Images depicting prolonged low precipitation causing water scarcity and impacting ecosystems or agriculture.
\item[5] \textbf{Extreme Storms and Tropical Cyclones}: Images showing severe weather with strong winds and heavy rain, including tropical cyclones.
\item[6] \textbf{Compound Events}: Images illustrating concurrent or sequential extreme events, such as combined heatwaves and droughts or heavy rains with storm surges.
\item[7] \textbf{Other}: Images that portray other types of extreme weather events not explicitly listed but relevant to the context of climate change.
\end{description}

Each image will be coded based on the primary weather event it represents, with the option to select 'Other' for images that depict extreme weather events not covered by the specific categories listed.

\subsubsection*{ENVIRO (Environmental Setting)}
\label{subsubsec:environmental-setting}
Environmental Setting reflects the location and setting of the event.
\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0] \textbf{Not Applicable}: The image does not convey a clear environmental context.
\item[1] \textbf{Urban}: Cityscapes, towns, or built-up areas.
\item[2] \textbf{Rural}: Countryside, farmlands, or sparsely populated areas.
\item[3] \textbf{Industrial}: Factories, energy plants or regions indicative of industrial human labour.
\item[4] \textbf{Polar Regions}: Icebergs, arctic landscapes, or antarctic expanses.
\item[5] \textbf{Forests}: Woodlands, rainforests, or jungle settings.
\item[6] \textbf{Water Bodies}: Oceans, lakes, or rivers.
\item[7] \textbf{Coastal Regions}: Beaches, coastlines, or others areas potentially affected by sea-level rise
\item[8] \textbf{Other}: Environmental settings not covered above.
\end{description}

Each image will be coded based on the primary environmental setting it represents, with the option to select 'Other' for images that depict environments not covered by the specific categories listed.

\noindent
Each image will be evaluated based on the primary weather event it appears to represent, with the option to select 'Other' for images that depict extreme weather events not covered by the specific categories listed.

\subsubsection*{ELEREP (Elemental Representation)}
\label{subsubsec:elemental-representation}
Elemental Representation categorises the primary elements or subjects featured in the image.
\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0] \textbf{Not Applicable}: No single element dominates the image.
\item[1] \textbf{Natural Landscape}: Natural environments like forests, oceans, or mountains.
\item[2] \textbf{Urban/Architectural}: Man-made structures, cities, or built environments.
\item[3] \textbf{Animal Life}: Prominent depiction of animals, wildlife, or fauna.
\item[4] \textbf{Energy Sources}: Focus on energy elements like solar panels, wind turbines, fossil fuels, coal plants etc.
\item[5] \textbf{Human Activity}: Human figures or activities.
\item[6] \textbf{Other}: Elements not specifically categorised above.
\end{description}

Each image will be coded based on the primary element it represents, with the option to select 'Other' for images that depict elements not covered by the specific categories listed.

\subsubsection*{PERSO (Personification)}
\label{subsubsec:personification}
Does the image personify climate change or its impacts? Personification in this context involves attributing human characteristics, emotions, or actions to non-human elements or abstract concepts related to climate change or its impacts. This includes scenarios where human figures or groups are central in the depiction of climate change, actively contributing to the image's meaning, such as portraying human emotions in response to climate phenomena or politicians discussing climate change.

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0] No.
\item[1] Yes.
\end{description}

\subsubsection*{SOLUT (Solution Visualisation)}
\label{subsubsec:solution-visualisation}
Are solutions or adaptations to the problem depicted? This includes portrayals of actions taken to mitigate or adapt to climate change, such as renewable energy sources (solar panels, wind turbines), reforestation, sustainable practices, or community initiatives. It also covers depictions of scientific or technological advancements aimed at addressing climate issues.

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0] No
\item[1] Yes
\end{description}

\subsubsection*{CHARA (Character Focus)}
\label{subsubsec:character-focus}
Character Focus identifies the primary subjects represented in the image. This includes human figures, groups, or symbolic entities that are central to the depiction of the event or its impacts. The focus is on understanding the types of characters used to personify or depict the narrative of the image, whether they are directly impacted by the event, representing a response to it, or symbolising broader concepts related to climate change. 

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0] \textbf{Not Applicable}: No discernible character focus.
\item[1] \textbf{Politicians}: Political figures or representations of governance.
\item[2] \textbf{Victims}: Individuals or groups suffering or in distress.
\item[3] \textbf{Activists}: Individuals or groups actively engaged in advocacy.
\item[4] \textbf{General Public}: Everyday people, crowds, or community members.
\item[5] \textbf{Scientists/ Experts}: Individuals portrayed as researchers or authorities on climate.
\item[6] \textbf{Health Professionals}: Individuals portrayed professionals from the health care industry.
\item[7] \textbf{Symbolic Figures}: Characters representing concepts like Mother Nature or future generations.
\item[8] \textbf{Other}: Any character focus not covered above.
\end{description}

Each image will be coded based on the primary character it represents, with the option to select 'Other' for images that depict elements not covered by the specific categories listed.

\subsubsection*{ENTIT (Affected Entities)}
\label{subsubsec:affected-entities}

This category focuses on identifying and classifying the entities that are depicted as being negatively affected in the AI-generated images. It seeks to understand the range and types of entities (e.g., humans, nature, infrastructure) that are impacted by the scenarios presented.

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0]\textbf{Not Applicable}: This category is used when there are no entities affected or represented in the image.
\item[1]\textbf{Human Impact}: Depicts impacts on individuals or communities.
\item[2]\textbf{Natural Impact}: Images showing the effects on natural elements like flora, fauna, landscapes, and ecosystems.
\item[3]\textbf{Infrastructural Impact}: Depictions of the impact on built environments, such as buildings, roads, bridges, etc.
\item[4]\textbf{Economic Impact}: Images portraying effects on economic aspects, including industries, markets, employment, and overall economic conditions.\footnote{Within this category, 'Economic Impact' specifically refers to negative effects on various economic elements. This encompasses images that depict downturns in industries or markets, job losses or negative labour dynamics, challenges in commercial sectors, financial crises, and adverse effects on global trade. The emphasis is on scenarios that visually represent economic struggles, recessions, or other detrimental effects on economic stability and growth}

\item[5]\textbf{Other}: For images that depict impacts on entities not covered by the above categories or where the impact is of a different nature.

\end{description}

Each image will be coded based on the primary entities it appears to affect, with the option to select 'Other' for images that depict entities not covered by the specific categories listed.

\subsubsection*{IMPACT (Impacts of Extreme Weather Events)}
\label{subsubsec:impact}
This category assesses the specific consequences and nature of impacts caused by extreme weather events as depicted in the images. It aims to understand the varied and multi-dimensional effects these events have on different aspects of life and the environment. 

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0]\textbf{Not Applicable}: This category is used when there is no impact shown in the image.
\item[1] \textbf{Health \& Well-being}: Focuses on the direct impact on human health, including physical injuries, fatalities, and mental health issues.
\item[2] \textbf{Home \& Livelihoods}: Addresses the socio-economic impacts such as homelessness, loss of income and displacement. Focuses on the challenges faced by individuals and communities in maintaining their standard of living and securing their basic needs after extreme weather events.
\item[3] \textbf{Environmental Damage}: Illustrates impacts on the natural environment, including pollution, landscape change and loss of biodiversity. This category emphasises the detrimental effects on ecosystems, wildlife habitats and the overall integrity of natural landscapes.
\item[4] \textbf{Infrastructural Breakdown}: Indicates the destruction or failure of critical infrastructure such as buildings, roads and bridges. This also includes the failure of important services and supply facilities, which impairs the normal functioning of the affected areas.
\item[5] \textbf{Economic Strain}: Examines the broader economic impact, such as financial hardship for individuals, market instability and challenges for different sectors. This includes both immediate economic losses and longer-term financial impacts.
\item[6] \textbf{Other}: Impacts not specifically covered above, or unique representations of the effects of extreme weather events.
\end{description}

\subsubsection*{ACTION (Action Depiction)}
\label{subsubsec:action-depiction}
Action Depiction categorises the types of activities or actions within the image that are related to the event.
\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0] \textbf{No Action Shown}: The image is static with no movement or activity depicted. It may be a landscape or a scene without any characters or dynamic elements.
\item[1] \textbf{Suffering}: Visual elements such as facial expressions, body language, or context suggest pain, distress, or hardship. This may include scenes showing the aftermath of a disaster or individuals in a state of despair.
\item[2] \textbf{Recovery Efforts}: Depicts individuals or groups actively engaging in reconstruction, medical aid, or providing assistance. Signs of activity include construction, medical care, or distribution of resources.
\item[3] \textbf{Prevention Measures}: Activities clearly aimed at preventing or lessening the impact of an event are shown. This could include barriers against floods, fire-fighting efforts, or vaccination campaigns.
\item[4] \textbf{Adaptation Strategies}: Strategies or technologies that suggest adjustments to living with the event's consequences. Examples could be houses built on stilts in flood-prone areas or use of renewable energy sources.
\item[5] \textbf{Other}: Includes any actions that do not fit into the above categories or are not immediately clear, such as abstract or symbolic representations of activity.
\end{description}

\subsubsection*{ENERG (Energy-Sources Visualisation)}
\label{subsubsec:solution-visualisation}
Are energy sources depicted in this image? If so which?
\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0] No
\item[1] \textbf{Renewable Energy}: Depictions focusing on sustainable energy sources such as solar panels, wind turbines, hydroelectric power.
\item[2] \textbf{Non-Renewable Energy}: Imagery emphasising traditional energy sources like fossil fuels, coal plants, oil rigs.
\item[3] Both
\end{description}

\subsubsection*{EVEREP (Event Representation)}
\label{subsubsec:event-representation}
Event Representation categorises how the image depicts the event, focusing on its visual portrayal and implied implications

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0] \textbf{Not Applicable}: Used for images without reference to a specific event, depicting generic or static scenes.
\item[1] \textbf{Destructive}: Indicates images emphasising destruction, chaos, or harm, including visible damage and human distress.
\item[2] \textbf{Manageable}: Suggests the event is under control, evidenced by emergency services, relief efforts, or resilient infrastructure.
\item[3] \textbf{Neutral}: For images presenting the event without a clear positive or negative perspective, often showing the event in progress.
\item[4] \textbf{Opportunistic}: Implies the event as a catalyst for positive developments, like community solidarity or environmental rejuvenation.
\item[5] \textbf{Other}: For images not covered in the above categories.
\end{description}

Each image will be coded based on the primary event it represents.

\subsection{Visual Composition}

The following variables pertain to the visual attributes of images produced by AI text-to-image models. These attributes are computed using a designated python script to provide a standardised quantitative assessment of the visual attributes present in each image in the dataset.

\subsubsection*{COLOR (Average Colour (RGB))}
\addcontentsline{toc}{subsubsection}{COLOR (Average Colour (RGB))}
This variable quantifies the average colour in the image, represented as RGB (Red, Green, Blue) values. Each component is measured on a scale from 0 to 255, where 0 denotes no colour presence and 255 signifies maximum intensity. To determine the average colour, the individual values of R, G, and B are summed and then divided by 3, providing a single number that reflects the combined intensity of all three colours.



\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] Low: The mean of RGB values is significantly lower than the mid-point (0 - 85). The distribution of values suggests muted or subdued colours.
\item[2] Medium: The mean of RGB values is around the mid-point (86 - 170). This range indicates a balanced level of colour intensity.
\item[3] High: The mean of RGB values is significantly higher than the mid-point (171 - 255). This end of the spectrum represents vivid and intense colours.
\end{description}

\subsubsection*{BRIGHT (Average Brightness)}
\addcontentsline{toc}{subsubsection}{BRIGHT (Average Brightness)}
This variable measures the overall brightness of the image. It is computed as the mean value of the 'Value' channel in the HSV (Hue, Saturation, Value) representation of the image. The scale ranges from 0 (complete darkness) to 255 (maximum brightness).

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] Low: Value channel average is significantly lower than the mid-point (0 - 127). This typically corresponds to a darker image.
\item[2] Medium: Value channel average is around the mid-point (128 - 191). This level of brightness is considered moderate.
\item[3] High: Value channel average is significantly higher than the mid-point (192 - 255). Such values suggest a very bright image.
\end{description}

\subsubsection*{SAT (Average Saturation)}
\addcontentsline{toc}{subsubsection}{SAT (Average Saturation)}
Saturation is the intensity of colour in the image. This variable captures the average saturation level, with 0 representing a lack of colour (grayscale) and 255 indicating the most vivid colour intensity possible.

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] Low: Saturation average is significantly lower than the mid-point (0 - 127). This indicates a lack of colour intensity, leaning towards a grayscale image.
\item[2] Medium: Saturation average is around the mid-point (128 - 191). Suggests moderate colour intensity.
\item[3] High: Saturation average is significantly higher than the mid-point (192 - 255). Represents highly saturated colours.
\end{description}

\subsection{Visual Synecdoches and Iconic Representation}
\label{subsec:visual-synecdoches}

This subchapter explores how AI models like \textit{DALL-E} and \textit{Midjourney} use visual synecdoches and iconic imagery to represent extreme weather events. The analysis focuses on identifying and interpreting common visual metaphors and symbols that have emerged as iconic representations in climate change communication.

\subsubsection*{SYNEC (Visual Synecdoche Identification)}
\label{subsubsec:synec}
This category involves identifying the presence of specific visual synecdoches or symbols in the imagery. It seeks to capture the use of iconic images like polar bears on melting ice, smokestacks emitting pollution, or barren landscapes, which have become shorthand for broader climate change narratives.

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[0] \textbf{Not Applicable}: The image does not contain any recognised visual synecdoches
\item[1] \textbf{Polar Imagery}: Includes images of polar bears, melting ice caps, or other arctic symbols.
\item[2] \textbf{Industrial Pollution}: Depictions of smokestacks, factories, or other industrial pollution symbols.
\item[3] \textbf{Renewable Energy}: Imagery of wind turbines, solar panels, or other symbols of sustainable energy.
\item[4] \textbf{Deforestation}: Images showing clear-cut forests or barren land.
\item[5] \textbf{Storms and Hurricanes}: Images showcasing hurricanes, cyclones, or severe storms, representing turbulent and destructive weather patterns.
\item[6] \textbf{Fire-Related Events}: Imagery of wildfires, forest fires, or burning landscapes, heat.
\end{description}