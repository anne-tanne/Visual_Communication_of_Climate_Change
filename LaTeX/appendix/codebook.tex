\subsection{Coding Unit}
The primary coding unit (CU) in this study is an individual image generated by AI models (\textit{DALL-E} and \textit{Midjourney}). Each image, created in response to a specific text prompt, is considered a distinct unit for analysis.

\textbf{Characteristics of the Coding Unit:
}
\begin{itemize}
    \item Images are directly sourced from the AI models without external content integration.
    \item \textbf{Uniqueness}: Each image is treated as a unique entity, distinct from others generated, even from similar prompts.
    \item \textbf{Completeness}: An image is considered complete as rendered by the AI model, without subsequent modifications or additions.
    \item \textbf{Relevance}: The image must be relevant to the prompt.
\end{itemize}

This definition ensures that each AI-generated image is analysed in its entirety, focusing on its relevance and alignment with the research themes.

\subsection{General Exclusion Criteria}
In the analysis of AI-generated images, certain categories of content are systematically excluded to maintain focus and relevance to the research questions. The following types of content will not be coded:

\begin{itemize}
    \item \textbf{Off-Topic Imagery:} Images that do not directly respond to the specific prompts given. The focus is on excluding images that are clearly unrelated to the specific prompt's context or subject, such as those depicting entirely unrelated subjects or settings.
    \item \textbf{Ineffective Text Generation:} Given the limitations of the AI models \textit{DALL-E} and \textit{Midjourney} in generating coherent and relevant text within images, this study excludes images where the primary focus is on text content. While images simply containing text (without it being the primary focus) are not excluded, the text itself is not analysed. The emphasis is on the visual elements and representations, not on the textual content within the images.
    \item \textbf{Technical Inadequacies:} Images suffering from poor rendering, low resolution, or other technical flaws that significantly hinder their analysis.
\end{itemize}


This exclusion criteria ensures the focus remains on relevant, appropriate, and analysable AI-generated imagery in the context of climate change and extreme weather events.

\subsection{Formal Categories}
 \subsubsection*{CU (Coding Unit)} 
 \addcontentsline{toc}{subsubsection}{CU (Coding Unit)}

 This represents a unique identifier for each individual image generated by the AI models. The ID is derived from the image's filename, for example, \texttt{1\_DALL-E}, signifying the first image created by DALL-E.
 
 \subsubsection*{CODER} 
  \addcontentsline{toc}{subsubsection}{CODER}

 This category lists the coders involved in the image analysis, each assigned a specific number for identification purposes.
\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] Anne-Sophie Skarabis
\item[2] Linda Murray
\end{description}

 \subsubsection*{MODEL} 
 \addcontentsline{toc}{subsubsection}{MODEL}

 This category indicates the AI model used to generate each image, distinguishing between the two different platforms used in this study.The model can be derived from the image's filename, for example, \texttt{19\_Midjourney}, signifying the 19th image created by Midjourney.

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] DALL-E 3
\item[2] Midjourney
\end{description}

 \subsubsection*{PROMPT} 
\addcontentsline{toc}{subsubsection}{PROMPT}

 The specific text prompt used for generating each image.

 \subsubsection*{DATE} 
 \addcontentsline{toc}{subsubsection}{DATE}

The date on which the image was generated.
\subsection{Narrative Constructs}

This section of the codebook is devoted to the analysis of the narratives constructed by the AI models in the imagery related to extreme weather events. It considers how these events are visually represented in terms of catastrophe, challenge, or opportunity.

\subsubsection*{EVENT (Event Portrayal)}
\addcontentsline{toc}{subsubsection}{EVENT (Event Portrayal)}
The portrayal of events in the images is coded according to the types and impacts of extreme weather events as described in the IPCC policy document. The codes are defined as follows:

\begin{description}[leftmargin=2.5cm, style = multiline, labelwidth=1.5cm]
\item[0] No Event: The image does not depict any recognisable weather-related event.
\item[1] Temperature Extremes: Images depicting unusually hot or cold temperatures, differing significantly from regional historical averages.
\item[2] Heavy Precipitation and Pluvial Floods: Images showing intense rainfall leading to rapid urban and pluvial flooding.
\item[3] River Floods: Images of excessive river and stream levels causing adjacent land inundation.
\item[4] Droughts: Images depicting prolonged low precipitation causing water scarcity and impacting ecosystems or agriculture.
\item[5] Extreme Storms and Tropical Cyclones: Images showing severe weather with strong winds and heavy rain, including tropical cyclones.
\item[6] Compound Events: Images illustrating concurrent or sequential extreme events, such as combined heatwaves and droughts or heavy rains with storm surges.
\item[7] Other: Images that portray other types of extreme weather events not explicitly listed but relevant to the context of climate change.
\end{description}


Each image will be evaluated based on the primary weather event it appears to represent, with the option to select 'Other' for images that depict extreme weather events not covered by the specific categories listed.


\subsection{Visual Composition}

The following variables pertain to the visual attributes of images produced by AI text-to-image models. These attributes are computed using a designated python script to provide a standardised quantitative assessment of the visual attributes present in each image in the dataset.

\subsubsection*{COLOR (Average Colour (RGB))}
\addcontentsline{toc}{subsubsection}{COLOR (Average Colour (RGB))}
This variable quantifies the average colour in the image, represented as RGB (Red, Green, Blue) values. Each component is measured on a scale from 0 to 255, where 0 denotes no colour presence and 255 signifies maximum intensity.


\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] Low: The mean of RGB values is significantly lower than the mid-point (0 - 85). The distribution of values suggests muted or subdued colours.
\item[2] Medium: The mean of RGB values is around the mid-point (86 - 170). This range indicates a balanced level of colour intensity.
\item[3] High: The mean of RGB values is significantly higher than the mid-point (171 - 255). This end of the spectrum represents vivid and intense colours.
\end{description}



\subsubsection*{BRIGHT (Average Brightness)}
\addcontentsline{toc}{subsubsection}{BRIGHT (Average Brightness)}
This variable measures the overall brightness of the image. It is computed as the mean value of the 'Value' channel in the HSV (Hue, Saturation, Value) representation of the image. The scale ranges from 0 (complete darkness) to 255 (maximum brightness).

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] Low: Value channel average is significantly lower than the mid-point (0 - 127). This typically corresponds to a darker image.
\item[2] Medium: Value channel average is around the mid-point (128 - 191). This level of brightness is considered moderate.
\item[3] High: Value channel average is significantly higher than the mid-point (192 - 255). Such values suggest a very bright image.
\end{description}



\subsubsection*{SAT (Average Saturation)}
\addcontentsline{toc}{subsubsection}{SAT (Average Saturation)}
Saturation is the intensity of colour in the image. This variable captures the average saturation level, with 0 representing a lack of colour (grayscale) and 255 indicating the most vivid colour intensity possible.

\begin{description}[leftmargin=2.5cm, style=multiline, labelwidth=1.5cm]
\item[1] Low: Saturation average is significantly lower than the mid-point (0 - 127). This indicates a lack of colour intensity, leaning towards a grayscale image.
\item[2] Medium: Saturation average is around the mid-point (128 - 191). Suggests moderate colour intensity.
\item[3] High: Saturation average is significantly higher than the mid-point (192 - 255). Represents highly saturated colours.
\end{description}




