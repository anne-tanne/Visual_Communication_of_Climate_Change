\section{Introduction}

In recent years, the discourse surrounding climate change has evolved from abstract predictions to an urgent reality marked by real-time observable impacts. Among the most visible and alarming manifestations of this global phenomenon is the increase in extreme weather events. These events, intensifying in frequency and severity \parencite{ipcc2023_wg1_11}, are altering ecosystems, impacting lives, and affecting economies globally \parencite[2460]{ipcc2023_wg2_16}. The Intergovernmental Panel on Climate Change (IPCC) has identified these changes as a direct consequence of climate change, highlighting the importance of effective communication for public understanding and engagement \parencite{ipcc2023_wg1_1}.

In climate change communication, visual representations are crucial. Images not only shape emotions but also influence behaviours towards climate change \parencite{Leiserowitz2006}. They enable a more rapid understanding of complex environmental risks \parencite{Epstein1994, Joffe2008} and encourage active participation over passive observation \parencite{Keib2018}. Furthermore, images are more memorable than text-only information \parencite{Coleman2009, Graber1990}, and can transcend linguistic and geographical barriers, if readers have the same cultural references \parencite{Armfield2013}.

Given this power of visual media, the emergence of advanced text-to-image models like \textit{OpenAI}â€™s \textit{DALL-E} or \textit{Midjourney} presents new prospects and challenges in climate communication. Text-to-image models harness machine-learning algorithms to transform textual prompts into detailed visual representations \parencite{Zhang2023}. There are two sides to this: These tools offer novel means of representation and image extraction, and thus an innovative way of presenting nuanced impacts and imagined scenarios of climate change. However, they also raise concerns about the authenticity and reliability of visual media.

The growing use of AI-generated content in journalism blurs the lines between AI and human-generated media \parencite{Henrich2023, Kim2023}. This trend highlights the need for guidelines to navigate these new technologies \parencite{CouncilOfEurope2023, SwissPressCouncil2023}.

Recent examples of AI-generated content in journalism \parencite{Henrich2023, Kim2023} indicate a growing trend where the lines between AI-created and human-made content are becoming increasingly blurred. This trend is emphasised by an emerging discourse about the urgent need for comprehensive guidelines to navigate this new terrain \parencite{CouncilOfEurope2023, SwissPressCouncil2023}. 

This paper investigates the use of AI-supported tools for visualising extreme weather events and explores how these technologies represent such events. While existing research has mainly focused on textual AI models like \textit{ChatGPT}, the role of AI in creating visual content, especially in scientific and climate communication, has yet not been researched much. This paper analyses outputs of extreme weather imagery from \textit{DALL-E 3} and \textit{Midjourney v6} ( hereinafter only referred to as \textit{DALL-E} and \textit{Midjourney}).
