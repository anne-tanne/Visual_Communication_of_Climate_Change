\section{Theoretical Foundations}
\label{section:theoretical-foundations}

\subsection{Generative Art and Text-to-Image Models}
\label{subsec:generative-art}

Generative art is the process by which an artist delegates control to an autonomous system, allowing it to either create a artwork or become the artwork itself \parencite[112]{Galanter2019}. While generative art commonly incorporates computers or digital technology, it is not strictly limited to these mediums \parencite[5]{Thomas2023}. Nonetheless, this paper defines "generative imagery" as imagery produced by text-to-image models. 

\subsubsection{Overview of Text-to-Image Models in AI}

Since 2022, text-to-image models like have seen significant advancements \parencite{Gozalo2023}. These models, which are part of generative machine learning, transform text into images. To achieve this, they are trained on extensive data sets combining images with descriptive texts and learn to correlate text elements with visual aspects \parencite{Bie2023}. For example, the word "mountain" in text is associated with certain shapes, colours, and textures in images. Through iterative adjustments during training, these models improve their ability to generate more accurate images from text.

Both \textit{DALL-E} and \textit{Midjourney} \parencite[5]{Thomas2023} provide user-friendly interfaces, with the latter's integration into \textit{Discord} potentially more challenging for users unfamiliar with the platform. Both models support 'prompt engineering' \parencite{Liu2022}, allowing iterative refinement for varied results, and can generate diverse images even from the same prompt.

\subsubsection{The Data Behind}
\label{sec:data-behind}

The effectiveness of text-to-image models is closely tied to their training data, which impacts the range and nature of generated images. Biased training data can result in AI-generated images mirroring and potentially reinforcing those biases. For instance, a model primarily trained on a specific newspaper's content may exhibit biases in style and thematic representation aligned with that source.

This reliance on pre-existing data for training AI models in image creation further raises ethical and legal concerns. Notably, in December 2023 \textit{The New York Times} sued \textit{OpenAI} for using its articles in training AI models without consent \parencite{Miller2023}. This case highlights concerns over copyright and raises questions about originality and intellectual property rights.

\subsubsection{Biases in Text-to-Image Model Outputs}
The field of communication science has only recently begun to examine the output of text-to-image models, reflecting the novelty of these technologies. During the literature review, only two relevant studies were found:

\textcite{Garcia2023} analysed gender stereotyping in images generated by \textit{DALL-E 2}, revealing a tendency for certain professions to be represented as either exclusively male or female, thereby echoing and potentially reinforcing traditional gender roles. \textcite{Thomas2023} analysed \textit{Midjourney}'s perceptions of "what a journalist looks like", uncovering biases related to gender, ethnicity, and age, neglecting diversity in modern journalism.

This tendency of AI models to replicate biases in their outputs can be traced back to the nature of their training data, as discussed in chapter \ref{sec:data-behind}. 

\subsection{Climate Change and Extreme Weather Events}
\label{subsec:climate-change-and-extreme-weather}

According to the \textcite{UNClimateChange}, climate change is characterised by long-term shifts in temperature and weather patterns. Since the 1800s, human activities have become the primary driver for climate change, largely due to greenhouse gases released by fossil fuel combustion, deforestation, and agriculture \parencite{ipcc2023_wg2_1}. This anthropogenic influence has led to systemic environmental disruptions, impacting various aspects of human life \parencite{ipcc_2023_policy}.

\subsubsection{Extreme Weather Events}
\label{subsubsec:extreme-weather}
An "extreme weather event" is a rare occurrence at a particular place and time of year \parencite[2908]{ipcc_2023_wg2_full}. Extreme weather encompasses various phenomena, as listed in Table~\ref{tab:extreme_weather_events}. These events, defined by their rarity compared to the 10th or 90th percentile of observations for their location \parencite[2908]{ipcc_2023_wg2_full}, may vary in length and persist for a season or longer. Global warming is amplifying these extremes, with even a modest increase (+0.5Â°C) having a significant impact on global weather patterns \parencite[1583]{ipcc2023_wg1_11}. The frequency of unprecedented extreme events is expected to increase with ongoing global warming.

\begin{table}[ht]
\centering
\renewcommand{\arraystretch}{1.5}
\begin{tabularx}{\linewidth}{|l|X|} % Use tabularx and set the table width to \linewidth
\hline
\rowcolor{gray!50}
\textbf{Event Type} & \textbf{Description} \\ \hline
\textbf{Temperature Extremes} & Unusually hot or cold temperatures, significantly differing from regional historical averages.\\ \hline

\textbf{Heavy Precipitation and Pluvial Floods} & Intense, rainfall over a short period leading to rapid urban and pluvial flooding.\\ \hline

\textbf{River Floods} & Excessive river and stream levels causing adjacent land inundation, often due to extended rainfall or snowmelt. \\ \hline

\textbf{Droughts} & Prolonged low precipitation causing water scarcity, impacting ecosystems and agriculture. \\ \hline

\textbf{Extreme Storms and Tropical Cyclones} & Severe weather with strong winds and heavy rain, including tropical cyclones originating over warm oceans. \\ \hline

\textbf{Compound Events} & Concurrent or sequential extreme events, such as combined heatwaves and droughts or heavy rains with storm surges. \\ \hline

\end{tabularx}
\caption[Types of Extreme Weather Events]{Types of Extreme Weather Events according to \textcite{ipcc_2023_policy}}
\label{tab:extreme_weather_events}
\end{table}


\subsubsection{Impacts of Climate Change and Extreme Weather}
\label{subsubsec:impacts-climate-change}

Climate change and extreme weather have far-reaching impacts on various regions and communities, affecting health, livelihoods, and well-being. These events can cause deaths, injuries, ecosystem or infrastructure damage \parencite[79]{ipcc_2023_technical}. They also have long-term consequences, such as mental health issues \parencite[1126]{ipcc2023_wg2_7}, homelessness \parencite[1251]{ipcc2023_wg2_8}, and reduced availability of health services \parencite[1632]{ipcc2023_wg2_11}.

Financially, extreme weather can increase constraints, pushing individuals into poverty and exacerbating inequality within countries. Vulnerable groups, particularly undocumented immigrants, Indigenous populations, and marginalised communities, are most at risk. They often face displacement, income loss, and home destruction, intensifying their vulnerability \parencite[1206]{ipcc2023_wg2_8}. One example of this are the Caribbean, Central America and the USA, where hurricanes Katrina, Harvey, Irma, Maria and Michael have led to the displacement, destruction of homes and loss of income among the poor and marginalised \parencite{Klinenberg2020}. Generally, the impacts of climate change and extreme weather events are disproportionately felt in the Global South \parencite[1180]{ipcc2023_wg2_8} \footnote{According to the Germanwatch Climate Risk Index (\citeyear{Germanwatch2021}),  the countries most affected by these events include Mozambique, Zimbabwe, The Bahamas, Japan, Malawi, the Islamic Republic of Afghanistan, India, South Soudan, Niger and Bolivia.}.

\subsection{Visual Communication of Climate Change}

Visual communication can be defined as the utilisation of visual elements to convey ideas and information. It stands apart from verbal or written languages due to its more abstract nature and the interpretation of visual signs being influenced by the viewer's field of experience \parencite{Smith2004}.

\subsubsection{Cognitive and Emotional Effects of Visuals}

In the area of climate change communication, visual representations are of great value. It has been shown that images not only influence people's feelings but also their behaviour in relation to climate change \parencite{Leiserowitz2006}. Images engage the holistic, intuitive and affective experience processing system, enabling a more rapid understanding of complex environmental risks \parencite{Epstein1994, Joffe2008}. This ability of images to swiftly convey information and evoke emotional responses not only increases media engagement but also shapes perceptions and behaviours towards climate change, thus catalysing the transition from passive spectatorship to active participation \parencite{Keib2018}. In addition, images help readers to remember information better than text-only information \parencite{Coleman2009, Graber1990} and provided the readers have similar cultural references, images can overcome linguistic or geographical barriers, when it comes to conveying information to an audience \parencite{Armfield2013}

Returning to the topic of generative image models discussed chapter \ref{subsec:generative-art}, their use in science communication offers both opportunities and challenges: For one thing, these AI tools can quickly produce visuals that could make scientific concepts more accessible. However, any inaccuracies could lead to misunderstandings or misinterpretations of scientific facts and generate scientific misinformation.

\subsubsection{Framing Climate Change}

According to \textcite{Sikorski2020}, "framing refers to the idea that actors like strategic communicators, journalists but also audience members select some aspects in a particular issue and make them salient while other aspects are ignored."

Whilst a "natural" consequence of the news process, framing always leads to certain effects, whether it is intentional or not \parencite[91]{ONeill2022}. For example, the prevailing frames can favour certain actors, influence the focus of media coverage and affect public opinion and political decisions \parencite{Nisbet2006}. 

This concept of framing extends beyond written or spoken media and is equally applicable to visual communications. Contrary to the common belief that a camera simply captures reality as it is, the truth is that images, too, can be instruments of framing \parencite[74]{ONeill2014}. For instance, showing only a part of an image without its broader context can significantly alter the perceived story, leading to misunderstandings or misinterpretations \parencite{Fleming2021}. Furthermore, different images can be used to portray the same underlying subject.

In framing, the narrative encompasses not just what is depicted, but also who is shown, the context provided, and the storyline conveyed. \textcite{ONeill2014} observed that when communicating climate change, legacy newspaper oftentimes use personification, such as the portrayal of politicians. Additionally, climate impacts are frequently illustrated in these depictions. Notably, what is rarely portrayed are aspects of climate mitigation or adaptation. This can be related back to news factor theory \parencite{Galtung1965}, where news factors such as "Personalisation" or "Negativity" increase the likelihood of a news story being chosen for publication, as they are more appealing to the audience. NGOs, in contrast, often focus on illustrating the dangers and triggers of climate change, using evocative polar regions to highlight environmental threats or images of renewable energy sources to emphasise the urgent need for sustainable solutions. Meanwhile, the advertising and marketing sectors use a diverse range of imagery that connects climate action with consumer behaviour, aiming to engage consumers and instill a sense of personal responsibility for climate action, influencing them to purchase their products. In each instance, the chosen frame and narrative serve the organisation's goals and influence public perception or action.

Building on this discussion, it is interesting to consider the role of text-to-image models. Different actors choose different frames to achieve their communication goals. These models, trained on existing datasets, have the potential to either maintain or challenge the established frames and narratives. Therefore, the following research question arises:

\begin{quote}
\textbf{RQ1}: What narratives do text-to-image models like \textit{DALL-E} and \textit{Midjourney} use when generating imagery related to extreme weather events? 
\end{quote}

This question explores the narratives constructed by these models, focusing on key aspects such as characters depicted, the types of consequences shown, and the overall context presented. The presence of a consistent frame/ narrative in generative imagery, especially if used in mass communications, could have significant impact. For example, if the images subtly embed bias or misinformation, they could unintentionally reinforce certain misconceptions and prejudices in the public consciousness.

\subsubsection{Visual Attributes }

The concept of framing can be further extended by looking at visual attributes or "visual modalities", defined by \textcite[256]{Kress2020} as the extent to which certain visual means of expression such as colour, depth or hue are used. Such visual attributes can affect an individual's emotions \parencite{Valdez1994} or even influence their behaviour \parencite{Meier2012}. Hence, the composition of visual attributes can have an impact on how an image is perceived.

This paper focuses on the aspects of colours, brightness and saturation. In their study on science conspiracy videos \textcite{Chen2022} found that conspiracy videos tended to use lower colour variances and lighting compared to correction videos, noting that this was particularly noticeable in the video thumbnails and first few seconds of the video. The researchers draw parallels between the visual features of conspiracy theories and horror films. Horror movies often use low-key lighting and a more limited, less saturated range of colours than other film genres \parencite{Rasheed2005}. This is typically done because dim lighting helps in building suspense, and darker colour is more fear inducing. 

Previous research has demonstrated that images related to climate change tend to elicit negative emotions rather than positive ones \parencite{ONeill2017}. Additionally, considering that there is an intrinsically frightening component to the issue of climate change and extreme weather events in particular \parencite{Soutar2022}, this paper investigates whether text-to-image models reinforce this narrative through their use of visual attributes associated with fear.
\begin{quote}
\textbf{RQ2}: Do the colour, brightness, and saturation levels typically employed in images generated by \textit{DALL-E} and \textit{Midjourney}, when depicting extreme weather events, align more with visual attributes that evoke fear? 
\end{quote}
\subsubsection{Visual Synecdoches and Iconic Imagery}

\textcite[16]{ONeill2019} found that as the visual language of climate change has evolved over the past decade, certain iconic images have also become increasingly common and embedded in the visual language. \textcite[17]{ONeill2019} refers to these iconic images as visual synecdoches, a kind of visual shorthand used in a particular culture to convey a certain set of ideas about climate change  to the reader beyond the conceptual content directly depicted. These images often represent the broader narrative of climate change in a single, impactful visual, making them instantly recognisable and emotionally resonant \parencite[78]{ONeill2014}. For instance, the image of a lone polar bear on a shrinking ice floe has become an iconic representation of the effects of global warming \parencite[18]{ONeill2019}. Other than polar bears, \textcite[16]{ONeill2019} identifies ice imagery, smokestacks and wind turbines to be common visual synecdoches.

This trend towards the use of visual synecdoches leads to the third research question:
 \begin{quote}
\textbf{RQ3}: In what ways do \textit{DALL-E} and \textit{Midjourney} use visual synecdoches to represent extreme weather events?

 \end{quote}

Lastly, in light of the three specific research questions addressed earlier, an overarching question emerges:

\begin{quote}
\textbf{RQ4}: Do \textit{DALL-E} and \textit{Midjourney} exhibit distinct differences in their portrayal of climate change narratives, visual attributes, and symbolic representations in the context of extreme weather events?
\end{quote}

This question aims to determine whether the results of the individual models are unique or whether they share common patterns in the representation of narratives about climate change.





